{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 本 p.82 `3-2-1` から作るrecord関数のColab版\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from pydub import AudioSegment\n",
        "import soundfile as sf\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "def record(duration):\n",
        "  \"\"\"PCのマイクで録音する関数\"\"\"\n",
        "\n",
        "  display(Javascript('''\n",
        "    const message = (text) => {\n",
        "      const domId = 'message';\n",
        "      const output = document.querySelector('#output-area');\n",
        "      let target = document.querySelector(`#${domId}`);\n",
        "      if (!target) {\n",
        "        target = document.createElement('div');\n",
        "        target.id = domId;\n",
        "        output.insertBefore(target, output.firstChild);\n",
        "      }\n",
        "      target.textContent = text;\n",
        "    };\n",
        "\n",
        "    const sleep = async (sec) => {\n",
        "      return new Promise(resolve => setTimeout(resolve, sec * 1000));\n",
        "    };\n",
        "\n",
        "    async function recordAudio(duration) {\n",
        "      const chunks = [];\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "      const recorder = new MediaRecorder(stream);\n",
        "      const fr = new FileReader();\n",
        "      recorder.ondataavailable = e => chunks.push(e.data);\n",
        "      recorder.onstop = e => fr.readAsDataURL(new Blob(chunks));\n",
        "      await recorder.start();\n",
        "      message('録音中･･･');\n",
        "      await sleep(duration);\n",
        "      await recorder.stop();\n",
        "      message('録音終了');\n",
        "      return await new Promise(resolve => {\n",
        "        fr.onloadend = () => resolve(fr.result);\n",
        "      });\n",
        "    }\n",
        "  '''))\n",
        "\n",
        "  data = eval_js(f'recordAudio({duration})')\n",
        "\n",
        "  # WAV形式に統一して読み込み\n",
        "  buffer = io.BytesIO()\n",
        "  AudioSegment.from_file(io.BytesIO(b64decode(data.split(',')[1]))).export(buffer, format=\"wav\")\n",
        "  buffer.seek(0)\n",
        "  waveform, sampling_rate = sf.read(\n",
        "    buffer,\n",
        "    dtype='int16' # 無指定なら自動で正規化されるが、あえて本と同じ正規化処理をするため指定\n",
        "  )\n",
        "\n",
        "  # バイトデータを数値データに変換\n",
        "  byte_to_num = np.frombuffer(waveform, dtype='int16')\n",
        "\n",
        "  # 最大値を計算\n",
        "  max_value = float((2 ** 16 / 2) - 1)\n",
        "\n",
        "  # 波形を正規化\n",
        "  normalized_waveform = byte_to_num / max_value\n",
        "\n",
        "  return normalized_waveform, sampling_rate\n",
        "\n",
        "print('録音準備完了')\n"
      ],
      "metadata": {
        "id": "UY4i-BX6tT-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 本 p.90 `3-2` をColab用に改変\n",
        "# 先にrecord関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "\n",
        "duration = 5\n",
        "waveform, sampling_rate = record(duration)\n",
        "print(len(waveform), waveform)\n"
      ],
      "metadata": {
        "id": "Hy-XtJC82BRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 本 p.91-94 `3-3` をColab用に改変\n",
        "# 実際のグラフはp.93のような滑らかなものでなくp.94にあるもの\n",
        "# 先にrecord関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def graph_plot(x, y):\n",
        "  \"\"\"波形をグラフにする関数\"\"\"\n",
        "\n",
        "  # グラフの設定\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.set_xlabel('Time[s]')\n",
        "  ax.set_ylabel('Amplitude')\n",
        "\n",
        "  # データのプロット\n",
        "  ax.plot(x, y)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "# 計測条件を設定して録音関数を実行\n",
        "duration = 5\n",
        "waveform, sampling_rate = record(duration)\n",
        "print(len(waveform), waveform, sampling_rate)\n",
        "\n",
        "# グラフをプロットする\n",
        "dt = 1 / sampling_rate\n",
        "t = np.arange(0, len(waveform) * dt, dt) # arrangeではない. array rangeの略\n",
        "graph_plot(t, waveform)\n"
      ],
      "metadata": {
        "id": "gC7Wa8YDGOl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 本 p.95-96 `3-4` をColab用に改変\n",
        "# 事前にrecord関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import soundfile as sf\n",
        "\n",
        "def graph_plot(x, y):\n",
        "  \"\"\"波形をグラフにする関数\"\"\"\n",
        "\n",
        "  # グラフの設定\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.set_xlabel('Time[s]')\n",
        "  ax.set_ylabel('Amplitude')\n",
        "\n",
        "  # データのプロット\n",
        "  ax.plot(x, y)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "# 計測条件を設定して録音関数を実行\n",
        "duration = 5\n",
        "waveform, sampling_rate = record(duration)\n",
        "print(len(waveform), waveform, sampling_rate)\n",
        "\n",
        "# グラフをプロットする\n",
        "dt = 1 / sampling_rate\n",
        "t = np.arange(0, len(waveform) * dt, dt) # arrangeではない. array rangeの略\n",
        "graph_plot(t, waveform)\n",
        "\n",
        "# wavファイルに保存する\n",
        "filename = 'recorded.wav'\n",
        "sf.write(filename, waveform, sampling_rate)\n"
      ],
      "metadata": {
        "id": "0UWOrZZ9fmiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 本 p.97-101 `3-5` をColab用に改変\n",
        "# 事前にrecord関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "def graph_plot(x, y):\n",
        "  \"\"\"波形をグラフにする関数\"\"\"\n",
        "\n",
        "  # グラフの設定\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.set_xlabel('Time[s]')\n",
        "  ax.set_ylabel('Amplitude')\n",
        "\n",
        "  # データのプロット\n",
        "  for x_axis, y_axis in zip(x, y):\n",
        "    ax.plot(x_axis, y_axis)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "# 計測条件を設定して録音関数を実行\n",
        "duration = 5\n",
        "waveform, sampling_rate = record(duration)\n",
        "print(len(waveform), waveform, sampling_rate)\n",
        "\n",
        "# グラフをプロットする\n",
        "dt = 1 / sampling_rate\n",
        "t = np.arange(0, len(waveform) * dt, dt) # arrangeではない. array rangeの略\n",
        "graph_plot([t], [waveform])\n",
        "\n",
        "# wavファイルに保存する\n",
        "filename = 'recorded.wav'\n",
        "sf.write(filename, waveform, sampling_rate)\n",
        "\n",
        "# ボイスチェンジする\n",
        "n_steps = 8\n",
        "waveform_shifted = librosa.effects.pitch_shift(waveform, sr=sampling_rate, n_steps=n_steps)\n",
        "\n",
        "# ピッチシフトされた音声を保存する\n",
        "sf.write('pitch_shifted.wav', waveform_shifted, sampling_rate)\n",
        "\n",
        "# 音声をグラフで比較する\n",
        "graph_plot([t, t], [waveform, waveform_shifted])"
      ],
      "metadata": {
        "id": "TcJY1lUk-lj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 前のセルに、ボイスチェンジ音声の再生を追加\n",
        "# 事前にrecord関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from IPython.display import Audio, display # 追加\n",
        "\n",
        "def graph_plot(x, y):\n",
        "  \"\"\"波形をグラフにする関数\"\"\"\n",
        "\n",
        "  # グラフの設定\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.set_xlabel('Time[s]')\n",
        "  ax.set_ylabel('Amplitude')\n",
        "\n",
        "  # データのプロット\n",
        "  for x_axis, y_axis in zip(x, y):\n",
        "    ax.plot(x_axis, y_axis)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "# 計測条件を設定して録音関数を実行\n",
        "duration = 5\n",
        "waveform, sampling_rate = record(duration)\n",
        "\n",
        "# グラフをプロットする\n",
        "dt = 1 / sampling_rate\n",
        "t = np.arange(0, len(waveform) * dt, dt) # arrangeではない. array rangeの略\n",
        "graph_plot([t], [waveform])\n",
        "\n",
        "# wavファイルに保存する\n",
        "filename = 'recorded.wav'\n",
        "sf.write(filename, waveform, sampling_rate)\n",
        "\n",
        "# ボイスチェンジする\n",
        "n_steps = 8\n",
        "waveform_shifted = librosa.effects.pitch_shift(waveform, sr=sampling_rate, n_steps=n_steps)\n",
        "\n",
        "# ピッチシフトされた音声を保存する\n",
        "sf.write('pitch_shifted.wav', waveform_shifted, sampling_rate)\n",
        "\n",
        "# 音声をグラフで比較する\n",
        "graph_plot([t, t], [waveform, waveform_shifted])\n",
        "\n",
        "# ボイスチェンジ音声を再生\n",
        "display(Audio(f'/content/pitch_shifted.wav', autoplay=True))\n"
      ],
      "metadata": {
        "id": "sMg5txTCQB2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 本 p.102 周波数分析 著者ブログのコードを利用しColab用に改変\n",
        "# 事前にrecord関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from scipy import fftpack\n",
        "\n",
        "def freq_graph_plot(x, y, labels):\n",
        "  \"\"\"周波数分析をグラフにする関数\"\"\"\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.set_xlabel('Frequency [Hz]')\n",
        "  ax.set_ylabel('Amplitude')\n",
        "  ax.set_yscale('log')\n",
        "  ax.set_xlim([0, 500])\n",
        "  for x_axis, y_axis, label in zip(x, y, labels):\n",
        "      ax.plot(x_axis, y_axis, label=label)\n",
        "  ax.legend()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def calc_fft(data, samplerate):\n",
        "  \"\"\"高速フーリエ変換（周波数分析）する関数\"\"\"\n",
        "\n",
        "  spectrum = fftpack.fft(data)\n",
        "  amp = np.sqrt((spectrum.real ** 2) + (spectrum.imag ** 2))\n",
        "  amp = amp / (len(data) / 2)\n",
        "  phase = np.arctan2(spectrum.imag, spectrum.real)\n",
        "  phase = np.degrees(phase)\n",
        "  freq = np.linspace(0, samplerate, len(data))\n",
        "\n",
        "  return amp, freq\n",
        "\n",
        "# 計測条件を設定して録音関数を実行\n",
        "duration = 5\n",
        "waveform, sampling_rate = record(duration)\n",
        "\n",
        "# ボイスチェンジする\n",
        "n_steps = 8\n",
        "waveform_shifted = librosa.effects.pitch_shift(waveform, sr=sampling_rate, n_steps=n_steps)\n",
        "\n",
        "# FFT（高速フーリエ変換）を計算\n",
        "original_amp, original_freq = calc_fft(waveform, sampling_rate)\n",
        "shifted_amp, shifted_freq = calc_fft(waveform_shifted, sampling_rate)\n",
        "\n",
        "# 周波数比較をグラフに描画\n",
        "freq_graph_plot(\n",
        "  [original_freq, shifted_freq],\n",
        "  [original_amp, shifted_amp],\n",
        "  ['recorded', 'pitch-shifted']\n",
        ")\n"
      ],
      "metadata": {
        "id": "GRCpWuqMAiTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 独自のrecord_auto_stop関数 (record関数の自動停止版、無音を検知するまで録音)\n",
        "# 参考 https://pavi2410.com/blog/detect-silence-using-web-audio/\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from pydub import AudioSegment\n",
        "import soundfile as sf\n",
        "import io\n",
        "\n",
        "error_count = 0\n",
        "\n",
        "def record_auto_stop(\n",
        "  SILENCE_RMS,      # 無音レベルの大きさの指標\n",
        "  SILENCE_SEC,      # 秒. 無音がこの時間続いたら録音終了\n",
        "):\n",
        "  display(Javascript('''\n",
        "\n",
        "    // メッセージ表示\n",
        "    const message = (text) => {\n",
        "      const domId = 'message';\n",
        "      const output = document.querySelector('#output-area');\n",
        "      let target = document.querySelector(`#${domId}`);\n",
        "      if (!target) {\n",
        "        target = document.createElement('div');\n",
        "        target.id = domId;\n",
        "        output.insertBefore(target, output.firstChild);\n",
        "      }\n",
        "      target.innerHTML += `${text}<br>`;\n",
        "    };\n",
        "\n",
        "    // 音量の指標を計算\n",
        "    const calculateRMS = (data) => {\n",
        "      let sum = 0;\n",
        "      for (let i = 0; i < data.length; i++) {\n",
        "        const normalized = data[i] / 128 - 1;\n",
        "        sum += normalized * normalized;\n",
        "      }\n",
        "      return Math.sqrt(sum / data.length);\n",
        "    };\n",
        "\n",
        "    async function recordAndAutoStop(SILENCE_RMS, SILENCE_SEC) {\n",
        "      // マイク使用可否チェック\n",
        "      let stream = null;\n",
        "      try {\n",
        "        stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "      } catch(e) {\n",
        "        return;\n",
        "      }\n",
        "\n",
        "      const audioContext = new AudioContext();\n",
        "      const source = audioContext.createMediaStreamSource(stream);\n",
        "      const analyser = audioContext.createAnalyser();\n",
        "      source.connect(analyser);\n",
        "\n",
        "      analyser.fftSize = 2048;\n",
        "      const bufferLength = analyser.fftSize;\n",
        "      const dataArray = new Uint8Array(bufferLength);\n",
        "      let silenceStart = performance.now();\n",
        "\n",
        "      const chunks = [];\n",
        "      const recorder = new MediaRecorder(stream);\n",
        "      recorder.ondataavailable = e => {\n",
        "        message('録音中');\n",
        "        chunks.push(e.data);\n",
        "      };\n",
        "\n",
        "      // 無音検知\n",
        "      const detectSilence = () => {\n",
        "        analyser.getByteTimeDomainData(dataArray);\n",
        "        if (calculateRMS(dataArray) < SILENCE_RMS) {\n",
        "          const now = performance.now();\n",
        "          if (now - silenceStart > (SILENCE_SEC * 10**3)) {\n",
        "            recorder.stop();\n",
        "            return;\n",
        "          }\n",
        "        } else {\n",
        "          silenceStart = performance.now();\n",
        "          if (recorder.state === 'inactive') {\n",
        "            recorder.start();\n",
        "          }\n",
        "        }\n",
        "        requestAnimationFrame(detectSilence);\n",
        "      }\n",
        "\n",
        "      const fr = new FileReader();\n",
        "      message('録音開始');\n",
        "      recorder.onstop = e => {\n",
        "        message('録音終了');\n",
        "        fr.readAsDataURL(new Blob(chunks))\n",
        "      };\n",
        "      recorder.start(1000);\n",
        "      detectSilence();\n",
        "\n",
        "      return await new Promise(resolve => {\n",
        "        fr.onloadend = () => resolve(fr.result);\n",
        "      });\n",
        "    };\n",
        "  '''))\n",
        "\n",
        "  data = eval_js(f'recordAndAutoStop({SILENCE_RMS}, {SILENCE_SEC})')\n",
        "\n",
        "  # 簡易エラー処理\n",
        "  global error_count\n",
        "  if data == None:\n",
        "    if error_count == 0:\n",
        "      error_count += 1\n",
        "      print('''\n",
        "        ブラウザ画面の中央にマイク使用を求める表示があると思います。\n",
        "        許可を選択し、もう一度セルを実行して下さい。\n",
        "        また別のマイク使用を求めるポップアップが出たら、許可して下さい。\n",
        "      '''.replace(' ', ''))\n",
        "    else:\n",
        "      print('マイクを使用できません')\n",
        "    return [], 0\n",
        "\n",
        "  # WAV形式に統一\n",
        "  buffer = io.BytesIO()\n",
        "  AudioSegment.from_file(\n",
        "    io.BytesIO(b64decode(data.split(',')[1]))\n",
        "  ).export(buffer, format=\"wav\")\n",
        "  buffer.seek(0)\n",
        "  return sf.read(buffer)\n",
        "\n",
        "print('録音準備完了')\n"
      ],
      "metadata": {
        "id": "zMOvEJp4Ydr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# record_auto_stop関数のテスト\n",
        "# 事前にrecord_auto_stop関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "SILENCE_RMS = 0.01 # 無音レベルの指標（環境音が大きければ増やす）\n",
        "SILENCE_SEC = 2    # 秒. 無音がこの時間続いたら録音終了\n",
        "\n",
        "try:\n",
        "  record_auto_stop\n",
        "except NameError:\n",
        "  print('先にrecord_auto_stop関数のセルの実行が必要です')\n",
        "else:\n",
        "  # 実行後、無音になるまで録音し再生\n",
        "  waveform, sampling_rate = record_auto_stop(SILENCE_RMS, SILENCE_SEC)\n",
        "\n",
        "  if len(waveform) > 0:\n",
        "    display(Audio(data=waveform, rate=sampling_rate, autoplay=True))\n"
      ],
      "metadata": {
        "id": "BLAsBzOiZGpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# record_auto_stop関数を使い、ボイスチェンジ音声を保存・再生\n",
        "# 事前にrecord_auto_stop関数のあるセルを実行（エラーが出ないことを確認）\n",
        "# ランタイム再起動したら関数セルを再実行する (面倒. Colab特有)\n",
        "# 初回実行時、録音完了から再生まで少し待つかも\n",
        "\n",
        "from IPython.display import Audio\n",
        "import librosa\n",
        "\n",
        "SILENCE_RMS = 0.01 # 無音レベルの指標（環境音が大きければ増やす）\n",
        "SILENCE_SEC = 2    # 秒. 無音がこの時間続いたら録音終了\n",
        "\n",
        "try:\n",
        "  record_auto_stop\n",
        "except NameError:\n",
        "  print('先にrecord_auto_stop関数のセルの実行が必要です')\n",
        "else:\n",
        "  # 実行後、無音になるまで録音\n",
        "  waveform, sampling_rate = record_auto_stop(SILENCE_RMS, SILENCE_SEC)\n",
        "\n",
        "  if len(waveform) > 0:\n",
        "    # ボイスチェンジ\n",
        "    n_steps = 8\n",
        "    waveform_shifted = librosa.effects.pitch_shift(\n",
        "      waveform, sr=sampling_rate, n_steps=n_steps\n",
        "    )\n",
        "\n",
        "    # ボイスチェンジ音声を再生\n",
        "    display(Audio(data=waveform_shifted, rate=sampling_rate, autoplay=True))\n"
      ],
      "metadata": {
        "id": "ssK82ZOZZGWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQJadxOo5YIs"
      },
      "outputs": [],
      "source": [
        "# NG例 1 Google Colab ではpyAudio を使えない\n",
        "# https://qiita.com/aikimasaki/items/6621c10c3d92a36b30ab\n",
        "# https://qiita.com/Gaudi1116/questions/26f9ff01ff2b30caad7b\n",
        "\n",
        "# インストールはできたが\n",
        "!apt install -y libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio\n",
        "\n",
        "import pyaudio\n",
        "\n",
        "# 音声デバイスを認識できない\n",
        "pa = pyaudio.PyAudio()\n",
        "print(pa.get_device_count())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NG例 2\n",
        "# https://qiita.com/aikimasaki/items/6621c10c3d92a36b30ab\n",
        "!pip install ipywebrtc\n",
        "\n",
        "from ipywebrtc import AudioRecorder\n",
        "import IPython\n",
        "import time\n",
        "\n",
        "recorder = AudioRecorder(recording=True)\n",
        "recorder.recording = True\n",
        "print('Started')\n",
        "time.sleep(3)\n",
        "recorder.recording = False\n",
        "print('Ended')\n",
        "# recorder.save('test.wav')\n",
        "# ValueError: No data, did you record anything?\n",
        "# 録音されてない. おそらく音声デバイスが認識されてない\n",
        "IPython.display.display(recorder.audio)\n"
      ],
      "metadata": {
        "id": "M12VPlMd7CnW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NG例 3 マイク認識されない\n",
        "\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "def reverse_audio(audio):\n",
        "  sr, data = audio\n",
        "  return (sr, np.flipud(data))\n",
        "\n",
        "mic = gr.Audio(\"microphone\", type=\"numpy\")\n",
        "gr.Interface(reverse_audio, mic, \"audio\").launch(debug=True)"
      ],
      "metadata": {
        "id": "Rtcpea6PKJQe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}